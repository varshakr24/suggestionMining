{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    '''\n",
    "    Lowercase, TOkenize (Stanford CoreNLP)\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    # Ref : https://github.com/Lynten/stanford-corenlp\n",
    "    nlp = StanfordCoreNLP(r'..\\pkgs\\stanford-corenlp-full-2016-10-31')\n",
    "    result = nlp.word_tokenize(text)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def train(model,train_loader,valid_loader,test_loader, numEpochs=5):\n",
    "    '''\n",
    "    Args:\n",
    "\n",
    "    Ret: \n",
    "    '''\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(numEpochs):\n",
    "        avg_loss = 0.0\n",
    "        for batch_num, (feats, labels) in enumerate(train_loader):\n",
    "            feats,labels = feats.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(feats)\n",
    "\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            if batch_num % 50 == 49:\n",
    "                print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch+1, batch_num+1, avg_loss/50))\n",
    "                avg_loss = 0.0\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            del feats\n",
    "            del labels\n",
    "\n",
    "    torch.save(model.state_dict(), \"jessi_A_\"+str(epoch)+\".pt\")\n",
    "\n",
    "    val_loss, val_acc = validate(model, valid_loader)\n",
    "    test_loss, test_acc = test(model, test_loader, epoch)\n",
    "    print('Epoch{:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}\\tTest Loss: {:.4f}\\tTest Accuracy: {:.4f}'.format(epoch, val_loss, val_acc, test_loss, test_acc))\n",
    "\n",
    "\n",
    "\n",
    "def validate(model, valid_loader):\n",
    "    '''\n",
    "    Args:\n",
    "\n",
    "    Ret:\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_num, (feats, labels) in enumerate(valid_loader):\n",
    "        feats,labels = feats.to(device), labels.to(device)\n",
    "        output = model(feats)\n",
    "\n",
    "        _, pred_labesl = torch.max(output, dim=1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "\n",
    "        #loss = criterion(output, labels.long())\n",
    "        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "        #test_loss.extend([loss.item()]*feats.size()[0])\n",
    "\n",
    "        #torch.cuda.empty_cache()\n",
    "        del feats\n",
    "        del labels\n",
    "\n",
    "    model.train()\n",
    "    #return np.mean(test_loss), accuracy/total\n",
    "    return 0, accuracy/total\n",
    "\n",
    "\n",
    "def test(model, test_loader, epoch):\n",
    "    '''\n",
    "    Args:\n",
    "\n",
    "    Ret:\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    \n",
    "    outcomes = []\n",
    "    \n",
    "    for batch_num, (feats, labels) in enumerate(test_loader):\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "        outputs = model(feats)[0]\n",
    "        \n",
    "        \n",
    "        _, pred_labels = torch.max(outputs, dim=1)\n",
    "        #loss = criterion(outputs, labels.long())\n",
    "        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "        #test_loss.extend([loss.item()]*feats.size()[0])\n",
    "        \n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        pred_labels = pred_labels.cpu()\n",
    "        pred_labels = np.array(pred_labels)\n",
    "        outcomes += [ [test_loader.dataset.samples[batch_num*BATCH_SIZE+i][0].split('/')[-1],\n",
    "            pred_labels[i]] for i in range(len(pred_labels)) ]\n",
    "        \n",
    "        del feats\n",
    "        del labels\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    f = open(\"Suggestion\"+str(epoch)+\".csv\", \"w\", newline=\"\")\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(outcomes)\n",
    "    f.close()\n",
    "    \n",
    "    #return np.mean(test_loss), accuracy/total\n",
    "    return 0, accuracy/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SuggestionDataset(Dataset):\n",
    "#     def __init__(self, filename):\n",
    "#         self.id_map = ID_Mapping(filename)\n",
    "        \n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.id_map)\n",
    "        \n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "        \n",
    "        \n",
    "import pathlib\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "ID_Mapping('as')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda65d29b067ab74d8c9fcb587724eb27cf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
