{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensembling",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "62xBKsU3jxdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "import os\n",
        "from csv import reader\n",
        "import re\n",
        "import pathlib\n",
        "import sys\n",
        "\n",
        "class DummyDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def __len__(self):\n",
        "        return 96\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        bert_embed = torch.tensor(np.zeros((1,300))).double()\n",
        "        glove_cove_embed = torch.tensor(np.zeros((1,600))).double()\n",
        "        return (bert_embed, glove_cove_embed), torch.tensor(0).double()\n",
        "\n",
        "    def get_map(self):\n",
        "        return self.id_map\n",
        "\n",
        "\n",
        "# sample = DummyDataset()\n",
        "# # #print(sample.__getitem__(0))\n",
        "# # train_loader =  torch.utils.data.DataLoader(sample, batch_size=32, \n",
        "# #                                                shuffle=True, num_workers=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "152QCQuKkJUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c94aef6e-8193-4bf9-84d5-2ba93c312e57"
      },
      "source": [
        "######################################################################\n",
        "#\n",
        "#   Architecture is as follows\n",
        "#   1. Bert word encoding + CNN with max pooling for sent.embed\n",
        "#   2. Glove & CoVe word Encoding  + CNN with attention for sent.embed\n",
        "#   3. (1) and (2) concated and fed to MLP for classification (1-sugg)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP,self).__init__()\n",
        "        self.l0 = nn.Linear(900,300) # BERT-> CNN (300), G,C->CNN (600)\n",
        "        self.l1 = nn.Linear(300,300)\n",
        "        self.l3 = nn.Linear(300,1)\n",
        "        self.dp = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # print(x.shape)\n",
        "        # print(x.type())\n",
        "        x = self.dp(F.sigmoid(self.l0(x)))\n",
        "        # print(x.shape)\n",
        "        x = self.dp(F.sigmoid(self.l1(x)))\n",
        "        # print(x.shape)\n",
        "        x = F.sigmoid(self.l3(x))\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n",
        "\n",
        "# class SuggestionClassifier(nn.Module):\n",
        "#     def __init_(self):\n",
        "#         # path all the models together\n",
        "#         # BERT->CNN + CNN->ATT\n",
        "#         super(SuggestionClassifier,self).__init__()\n",
        "#         # self.CNN_b = CNN_BERT()\n",
        "#         # self.CNN_gc = CNN_GC()\n",
        "#         self.MLP = MLP()\n",
        "\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # bert_x = self.CNN_b(x[0])\n",
        "#         # gc_x = self.CNN_gc(x[1])\n",
        "#         bert_x = x[0]\n",
        "#         gc_x = x[1]\n",
        "        \n",
        "#         out = torch.cat(bert_x,gc_x) # TODO : ensure dimensions align (1x300, 1x600)\n",
        "#         out = self.MLP(out) # Dim : 1x900\n",
        "#         return out\n",
        "\n",
        "\n",
        "#############################\n",
        "# HELPER FUNCTIONS\n",
        "\n",
        "def train(model, train_loader, valid_loader, test_loader, foldId, numEpochs=5):\n",
        "    '''\n",
        "    Args:\n",
        "\n",
        "    Ret: \n",
        "    '''\n",
        "\n",
        "    model.train()\n",
        "    val_loss_min = None\n",
        "    val_loss_min_delta = 0\n",
        "    val_patience = 0\n",
        "    val_loss_counter = 0\n",
        "\n",
        "    # TODO : 10-fold cross validation (build 10 models)\n",
        "    # TODO : Ensemble, pick top three models based on train loss\n",
        "    # TODO : Voting Mechanism to evaluate on Validation data\n",
        "    \n",
        "    # for each fold\n",
        "    #     for each epoch\n",
        "    #       min_batch_train(model)\n",
        "    #       val_loss = model(trial_data)\n",
        "    #       early_stopping(val_loss)\n",
        "    #     models += models\n",
        "    #     three_models = select_best_3(models) based on train_loss\n",
        "        \n",
        "    for epoch in range(numEpochs):\n",
        "        avg_loss = 0.0\n",
        "        for batch_num, (feats, labels) in enumerate(train_loader):\n",
        "\n",
        "            #print(feats[0].size())\n",
        "            #print(feats[0].permute(2,1,0).size())\n",
        "            feats = torch.cat((feats[0].permute(2,1,0),feats[1].permute(2,1,0))).permute(2,1,0)\n",
        "\n",
        "            feats,labels = feats.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(feats)\n",
        "            print(outputs.shape)\n",
        "            loss = criterion(outputs, labels.view(BATCH_SIZE,1).long())\n",
        "            print(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print(\"Optimizer Complete\")\n",
        "\n",
        "            avg_loss += loss.item()\n",
        "            print(avg_loss)\n",
        "\n",
        "            if batch_num % 50 == 49:\n",
        "                print('Fold: {}\\t Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(foldId+1, epoch+1, batch_num+1, avg_loss/50))\n",
        "                avg_loss = 0.0\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            del feats\n",
        "            del labels\n",
        "\n",
        "        model_name = \"jessi_A_fold_\"+str(foldId+1)+\"_epoch_\"+str(epoch+1)+\".pt\"\n",
        "        print(model_name)\n",
        "        torch.save(model.state_dict(), model_name)\n",
        "\n",
        "        val_loss, val_acc = validate(model, valid_loader)\n",
        "        test_loss, test_acc = validate(model, test_loader)\n",
        "        print('Epoch{:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}\\tTest Loss: {:.4f}\\tTest Accuracy: {:.4f}'.format(epoch, val_loss, val_acc, test_loss, test_acc))\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss_min is None:\n",
        "            val_loss_min = val_loss\n",
        "        elif val_loss_min >= (val_loss + val_loss_min_delta) :\n",
        "            val_loss_counter += 1\n",
        "            if (val_loss_counter > val_patience) :\n",
        "                print(\"Validation Loss: {}\\t Lowest Validation Loss {}\\t\".format(val_loss, val_loss_min))\n",
        "                print(\"Training stopped early, Epoch :\"+str(epoch))\n",
        "                break\n",
        "        else:\n",
        "            val_loss_min = val_loss\n",
        "\n",
        "    return test_acc, model_name\n",
        "\n",
        "\n",
        "def validate(model, valid_loader):\n",
        "    '''\n",
        "    Args:\n",
        "\n",
        "    Ret:\n",
        "    '''\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = []\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_num, (feats, labels) in enumerate(valid_loader):\n",
        "        feats = torch.cat((feats[0].permute(2,1,0),feats[1].permute(2,1,0))).permute(2,1,0)\n",
        "        feats,labels = feats.to(device), labels.to(device)\n",
        "        outputs = model(feats)\n",
        "\n",
        "        pred_labels = torch.round(outputs)\n",
        "        pred_labels = pred_labels.view(-1)\n",
        "\n",
        "        loss = criterion(outputs, labels.view(BATCH_SIZE,1).long())\n",
        "        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "        total += len(labels)\n",
        "        test_loss.extend([loss.item()]*feats.size()[0])\n",
        "\n",
        "        #torch.cuda.empty_cache()\n",
        "        del feats\n",
        "        del labels\n",
        "\n",
        "    model.train()\n",
        "    return np.mean(test_loss), accuracy/total\n",
        "    #return 0, accuracy/total\n",
        "\n",
        "\n",
        "def test(models, test_loader, id_map=0):\n",
        "    '''\n",
        "    Args:\n",
        "\n",
        "    Ret:\n",
        "    '''\n",
        "\n",
        "    test_loss = []\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "    \n",
        "    outcomes = []\n",
        "    \n",
        "    for batch_num, (feats, labels) in enumerate(test_loader):\n",
        "        #print(feats[0].size())\n",
        "        feats = torch.cat((feats[0].permute(2,1,0),feats[1].permute(2,1,0))).permute(2,1,0)\n",
        "        feats, labels = feats.to(device), labels.to(device)\n",
        "        predictions = torch.tensor(np.zeros(len(labels))).to(device)\n",
        "\n",
        "        for model in models:\n",
        "            model = model.double()\n",
        "            model.eval()\n",
        "            outputs = model(feats)\n",
        "            pred_labels = torch.round(outputs)\n",
        "            predictions += pred_labels.view(-1)\n",
        "            model.train()\n",
        "\n",
        "        predictions = torch.round(predictions/3)\n",
        "        accuracy += torch.sum(torch.eq(predictions, labels)).item()\n",
        "        total += len(labels)       \n",
        "        # outcomes += [ [id_map(test_loader.dataset.samples[batch_num * BATCH_SIZE + i]),predictions[i]] for i in range(len(predictions)) ]\n",
        "            \n",
        "        del feats\n",
        "        del labels\n",
        "    \n",
        "    # f = open(\"Suggestion.csv\", \"w\", newline=\"\")\n",
        "    # writer = csv.writer(f)\n",
        "    # writer.writerows(outcomes)\n",
        "    # f.close()\n",
        "    \n",
        "    #return np.mean(test_loss), accuracy/total\n",
        "    return -1, accuracy/total\n",
        "\n",
        "\n",
        "#########################\n",
        "# HYPER PARAMETER TUNING\n",
        "\n",
        "NUM_EPOCHS = 1\n",
        "WEIGHT_DECAY = 3\n",
        "BATCH_SIZE = 32\n",
        "NFOLDS = 10\n",
        "NUM_WORKERS = 1\n",
        "LEARNING_RATE = 0.1 # TODO : Experiment, as LR not given\n",
        "\n",
        "########################\n",
        "# MODEL CREATION\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "        torch.nn.init.kaiming_normal_(m.weight.data)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MLP()\n",
        "# TODO:  WEIGHT INIT\n",
        "model.apply(init_weights)\n",
        "model = model.double()\n",
        "model.train()\n",
        "model.to(device)\n",
        "\n",
        "#######################\n",
        "# OPTIMIZATION\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "########################\n",
        "# DATA LOADING\n",
        "\n",
        "# valid_dataset = SuggestionDataset(load_data(filename=\"SubtaskA_Trial_Test_Labeled.csv\"))\n",
        "valid_dataset = DummyDataset()\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, \n",
        "                                               shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "# test_dataset = SuggestionDataset(load_data(filename=\"SubtaskA_EvaluationData_labeled.csv\"), mode=0)\n",
        "# test_id_map = test_dataset.get_map()\n",
        "test_dataset = DummyDataset()\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, \n",
        "                                               shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "# data = load_data()\n",
        "# data_folds = create_folds(data)\n",
        "model_perfs = []\n",
        "model_names = []\n",
        "for i in range(NFOLDS):\n",
        "    # train, test = create_cross_val_train_test(data_folds,i)\n",
        "    # train_dataset = SuggestionDataset(train)\n",
        "    train_dataset = DummyDataset()\n",
        "    train_loader =  torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
        "                                               shuffle=True, num_workers=NUM_WORKERS)\n",
        "    # test_dataset = SuggestionClassifier(test)\n",
        "    test_dataset = DummyDataset()\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, \n",
        "                                               shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "    test_loss, model_name = train(model, train_loader, valid_loader, test_loader, i, NUM_EPOCHS)\n",
        "\n",
        "    model_perfs.append(test_loss)\n",
        "    model_names.append(model_name)\n",
        "\n",
        "\n",
        "print(model_perfs)\n",
        "print(model_names)\n",
        "best_three_model_idx = np.flip(np.argsort(model_perfs))[0:3]\n",
        "models = []\n",
        "for idx in best_three_model_idx:\n",
        "    # load the model\n",
        "    #temp_model = SuggestionClassifier()\n",
        "    temp_model = MLP()\n",
        "    temp_model.load_state_dict(torch.load(model_names[idx]))\n",
        "    models.append(temp_model)\n",
        "# testing\n",
        "print(len(models))\n",
        "test(models, test_loader)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "jessi_A_fold_1_epoch_1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch0.0000\tVal Loss: 0.0000\tVal Accuracy: 1.0000\tTest Loss: 0.0000\tTest Accuracy: 1.0000\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "jessi_A_fold_2_epoch_1.pt\n",
            "Epoch0.0000\tVal Loss: 0.0000\tVal Accuracy: 1.0000\tTest Loss: 0.0000\tTest Accuracy: 1.0000\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "jessi_A_fold_3_epoch_1.pt\n",
            "Epoch0.0000\tVal Loss: 0.0000\tVal Accuracy: 1.0000\tTest Loss: 0.0000\tTest Accuracy: 1.0000\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "jessi_A_fold_4_epoch_1.pt\n",
            "Epoch0.0000\tVal Loss: 0.0000\tVal Accuracy: 1.0000\tTest Loss: 0.0000\tTest Accuracy: 1.0000\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "jessi_A_fold_5_epoch_1.pt\n",
            "Epoch0.0000\tVal Loss: 0.0000\tVal Accuracy: 1.0000\tTest Loss: 0.0000\tTest Accuracy: 1.0000\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "jessi_A_fold_6_epoch_1.pt\n",
            "Epoch0.0000\tVal Loss: 0.0000\tVal Accuracy: 1.0000\tTest Loss: 0.0000\tTest Accuracy: 1.0000\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "jessi_A_fold_7_epoch_1.pt\n",
            "Epoch0.0000\tVal Loss: 0.0000\tVal Accuracy: 1.0000\tTest Loss: 0.0000\tTest Accuracy: 1.0000\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "jessi_A_fold_8_epoch_1.pt\n",
            "Epoch0.0000\tVal Loss: 0.0000\tVal Accuracy: 1.0000\tTest Loss: 0.0000\tTest Accuracy: 1.0000\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "jessi_A_fold_9_epoch_1.pt\n",
            "Epoch0.0000\tVal Loss: 0.0000\tVal Accuracy: 1.0000\tTest Loss: 0.0000\tTest Accuracy: 1.0000\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "torch.Size([32, 1, 1])\n",
            "tensor(0., dtype=torch.float64, grad_fn=<NllLoss2DBackward>)\n",
            "Optimizer Complete\n",
            "0.0\n",
            "jessi_A_fold_10_epoch_1.pt\n",
            "Epoch0.0000\tVal Loss: 0.0000\tVal Accuracy: 1.0000\tTest Loss: 0.0000\tTest Accuracy: 1.0000\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "['jessi_A_fold_1_epoch_1.pt', 'jessi_A_fold_2_epoch_1.pt', 'jessi_A_fold_3_epoch_1.pt', 'jessi_A_fold_4_epoch_1.pt', 'jessi_A_fold_5_epoch_1.pt', 'jessi_A_fold_6_epoch_1.pt', 'jessi_A_fold_7_epoch_1.pt', 'jessi_A_fold_8_epoch_1.pt', 'jessi_A_fold_9_epoch_1.pt', 'jessi_A_fold_10_epoch_1.pt']\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}