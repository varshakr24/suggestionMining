{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensembling_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WbNNIzg1wuM",
        "colab_type": "code",
        "outputId": "42d01b00-4761-461a-971d-ddddeba54aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/salesforce/cove.git # use ssh: git@github.com:salesforce/cove.git\n",
        "!cd cove\n",
        "!pip install -r cove/requirements.txt\n",
        "!python cove/setup.py develop\n",
        "!pip install transformers\n",
        "# On CPU"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cove'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Total 130 (delta 0), reused 0 (delta 0), pack-reused 130\u001b[K\n",
            "Receiving objects: 100% (130/130), 47.54 KiB | 3.66 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "Collecting git+git://github.com/jekbradbury/revtok.git (from -r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 14))\n",
            "  Cloning git://github.com/jekbradbury/revtok.git to /tmp/pip-req-build-f1fzdr3z\n",
            "  Running command git clone -q git://github.com/jekbradbury/revtok.git /tmp/pip-req-build-f1fzdr3z\n",
            "Collecting git+https://github.com/pytorch/text.git (from -r cove/requirements.txt (line 2))\n",
            "  Cloning https://github.com/pytorch/text.git to /tmp/pip-req-build-4qa11won\n",
            "  Running command git clone -q https://github.com/pytorch/text.git /tmp/pip-req-build-4qa11won\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 2)) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 5)) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from -r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 8)) (1.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 11)) (3.2.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (2.2.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Sphinx in /usr/local/lib/python3.6/dist-packages (from -r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (1.8.5)\n",
            "Collecting sphinx_rtd_theme\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/b4/4df37087a1d36755e3a3bfd2a30263f358d2dea21938240fa02313d45f51/sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 50.0MB/s \n",
            "\u001b[?25hCollecting flake8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/1f/7ea40d1e4146ea55dbab41cda1376db092a75794914169aabd7e8d7a7def/flake8-3.7.9-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from -r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 26)) (3.6.4)\n",
            "Collecting pytest-pythonpath\n",
            "  Downloading https://files.pythonhosted.org/packages/46/c1/4b784495bb316962962df191b3c1b2302c60236301406283a9de1470786f/pytest-pythonpath-0.7.3.tar.gz\n",
            "Collecting pytest-cov\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/54/3673ee8be482f81527678ac894276223b9814bb7262e4f730469bb7bf70e/pytest_cov-2.8.1-py2.py3-none-any.whl\n",
            "Collecting codecov\n",
            "  Downloading https://files.pythonhosted.org/packages/4d/86/7135a1db448c3bd478a7bbd817bfe3d80200eec7a89d320d574644879528/codecov-2.0.22-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5.1->-r cove/requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5.1->-r cove/requirements.txt (line 2)) (1.18.2)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 5)) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 5)) (2.8)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (46.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (7.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 13)) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 13)) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 13)) (0.14.1)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (2.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (20.3)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (2.11.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (2.1.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (2.0.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (0.15.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (1.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (1.2.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (0.7.12)\n",
            "Collecting pyflakes<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/f2/ed0ffb887f8138a8fe5a621b8c0bb9598bfb3989e029f6c6a85ee66628ee/pyflakes-2.1.1-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n",
            "\u001b[?25hCollecting pycodestyle<2.6.0,>=2.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from flake8->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 23)) (0.3)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 26)) (19.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 26)) (1.8.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 26)) (1.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 26)) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 26)) (8.2.0)\n",
            "Collecting coverage>=4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/8a/b190b4cafb8d94c518efb22f561326b5b7e045f13133ec2d482fce395dd0/coverage-5.0.4-cp36-cp36m-manylinux1_x86_64.whl (227kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 71.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (1.6.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (2.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->Sphinx->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 17)) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->-r https://raw.githubusercontent.com/pytorch/text/master/requirements.txt (line 12)) (3.1.0)\n",
            "Building wheels for collected packages: sacremoses, pytest-pythonpath, revtok, torchtext\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=5d14531d07bf94e2b575d34ee8bf918885784c385cfdf99af75b62cc71248348\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "  Building wheel for pytest-pythonpath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytest-pythonpath: filename=pytest_pythonpath-0.7.3-cp36-none-any.whl size=3049 sha256=323b6ca7b907d326acd354bb7e0e46db6c272e5aabf1cf8d544298bd698bb878\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/b3/f2/c71e3d66868019a971d07924a12a2d28e65694bfeaac95ac77\n",
            "  Building wheel for revtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for revtok: filename=revtok-0.0.3-cp36-none-any.whl size=5183 sha256=c342c848d6270db68a32f916ab1d057b17a73af49c4f7f2a1b0a816247538de7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-83izx5u9/wheels/7a/ea/8a/6728347664cd622aaf563f3a46e68338f671f30c1b642006f2\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.5.1-cp36-none-any.whl size=64241 sha256=2d17d3727519754c3b8fe0cb5d69e2f164af27fece0830460afb52df6a9b0f63\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-83izx5u9/wheels/09/f9/ed/0e37c2b62298f9b1225412431e805e89206cbde3a0bac44327\n",
            "Successfully built sacremoses pytest-pythonpath revtok torchtext\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement coverage==3.7.1, but you'll have coverage 5.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: coveralls 0.5 has requirement coverage<3.999,>=3.6, but you'll have coverage 5.0.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, sphinx-rtd-theme, pyflakes, pycodestyle, mccabe, flake8, pytest-pythonpath, coverage, pytest-cov, codecov, revtok, sentencepiece, torchtext\n",
            "  Found existing installation: coverage 3.7.1\n",
            "    Uninstalling coverage-3.7.1:\n",
            "      Successfully uninstalled coverage-3.7.1\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed codecov-2.0.22 coverage-5.0.4 flake8-3.7.9 mccabe-0.6.1 pycodestyle-2.5.0 pyflakes-2.1.1 pytest-cov-2.8.1 pytest-pythonpath-0.7.3 revtok-0.0.3 sacremoses-0.0.38 sentencepiece-0.1.85 sphinx-rtd-theme-0.4.3 torchtext-0.5.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "running develop\n",
            "running egg_info\n",
            "creating cove.egg-info\n",
            "writing cove.egg-info/PKG-INFO\n",
            "writing dependency_links to cove.egg-info/dependency_links.txt\n",
            "writing top-level names to cove.egg-info/top_level.txt\n",
            "writing manifest file 'cove.egg-info/SOURCES.txt'\n",
            "reading manifest file 'cove.egg-info/SOURCES.txt'\n",
            "writing manifest file 'cove.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.6/dist-packages/cove.egg-link (link to .)\n",
            "Adding cove 1.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /content\n",
            "Processing dependencies for cove==1.0.0\n",
            "Finished processing dependencies for cove==1.0.0\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.31)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 61.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.31)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.1)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.5.2 transformers-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "62xBKsU3jxdt",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from csv import reader\n",
        "import csv\n",
        "import re\n",
        "import pathlib\n",
        "import sys\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import GloVe\n",
        "from cove import cove\n",
        "from transformers import AutoTokenizer, BertModel, DistilBertModel\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv2fTIx91sqp",
        "colab_type": "code",
        "outputId": "7504f123-bb1a-47cc-fdba-790f1a680153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!tar -xvf /content/jessi.tar "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jessi_A_fold_1_epoch_10.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVddt0XxNSu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bert Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
        "\n",
        "MAX_LEN_GC = 350\n",
        "MAX_LEN_B = 256\n",
        "\n",
        "def tokenizerfnc(str):\n",
        "    return tokenizer.encode(str,max_length=MAX_LEN_B, pad_to_max_length=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvqvvvIeNSvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_GC(nn.Module):\n",
        "\n",
        "    def __init__(self,out_dim=200,gc_dim=900,max_len=MAX_LEN_GC, dropout=0.5):\n",
        "        super(CNN_GC, self).__init__()\n",
        "        \n",
        "        \"\"\"cove_model = CoVeEmbeddings(\n",
        "            word_embeddings_dir='../model/text/stanford/glove/', \n",
        "            tokenizer=tokenizer,\n",
        "            max_sequence_length=max_len, verbose=20)\n",
        "        glove_model = GloVeEmbeddings()\n",
        "        glove_model.load_model(dest_dir='../model/text/stanford/glove/', process=False)\"\"\"\n",
        "        \n",
        "        self.gc_dim = gc_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.max_len = max_len\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.conv_3 = nn.Conv1d(gc_dim, out_dim, 3, stride=1, padding=1)\n",
        "        self.conv_5 = nn.Conv1d(gc_dim, out_dim, 5, stride=1, padding=2)\n",
        "        self.conv_7 = nn.Conv1d(gc_dim, out_dim, 7, stride=1, padding=3)\n",
        "        self.attn = nn.Linear(3*out_dim*max_len, max_len)\n",
        "\n",
        "    def forward(self,x):\n",
        "        #cove_embed = cove_model.encode(x)\n",
        "        #tokens = [sentence.split(\" \") for sentence in x]\n",
        "        #glove_embed = glove_model.encode(tokens)\n",
        "        #x = torch.cat([cove_embed,glove_embed], 2)\n",
        "        \n",
        "        conv_3 = F.relu(self.conv_3(x))\n",
        "        conv_5 = F.relu(self.conv_5(x))\n",
        "        conv_7 = F.relu(self.conv_7(x))\n",
        "        x = torch.cat([conv_3,conv_5,conv_7], 1)\n",
        "        #print(x.shape)\n",
        "        \n",
        "        non_linear_x = F.relu(x.view(-1, 600*self.max_len))\n",
        "        #print(non_linear_x.shape)\n",
        "        attn_weights = F.softmax(self.attn(non_linear_x), dim=1)\n",
        "        #print(attn_weights.shape)\n",
        "        #attn_applied = torch.bmm(attn_weights.unsqueeze(1), x)\n",
        "        #attn_applied = attn_weights*x\n",
        "        attn_applied = torch.zeros(x.shape[0], x.shape[1], x.shape[2]).to(device)\n",
        "        for i in range(x.shape[0]):\n",
        "            attn_applied[i,:,:] = x[i,:,:]*attn_weights[i]\n",
        "        #print(\"hello\")\n",
        "        #print(attn_applied.shape)\n",
        "        \n",
        "        x = attn_applied.sum(dim=2)\n",
        "        del attn_applied\n",
        "        return x\n",
        "    \n",
        "class CNN_BERT(nn.Module):\n",
        "\n",
        "    def __init__(self, out_dim=100, embed_dim=768, max_len=MAX_LEN_B, dropout=0.5):\n",
        "        super(CNN_BERT, self).__init__()\n",
        "        \n",
        "        self.embed_dim = embed_dim\n",
        "        self.out_dim = out_dim # not 100?\n",
        "        self.max_len = max_len # ?\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.bert_layer = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.conv_3 = nn.Conv1d(1, out_dim, embed_dim * 3, stride=embed_dim)\n",
        "        self.conv_4 = nn.Conv1d(1, out_dim, embed_dim * 4, stride=embed_dim)\n",
        "        self.conv_5 = nn.Conv1d(1, out_dim, embed_dim * 5, stride=embed_dim)\n",
        "\n",
        "    def get_conv_out(self,conv,x, num):\n",
        "        return F.max_pool1d(F.relu(conv(x)), \n",
        "                            self.max_len - num + 1).view(-1, self.out_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.bert_layer(x)\n",
        "        #print('bert')\n",
        "        #print(x)\n",
        "        x = x[0].view(-1, 1, self.embed_dim * self.max_len)\n",
        "        conv_3 = self.get_conv_out(self.conv_3, x, 3)\n",
        "        conv_4 = self.get_conv_out(self.conv_4, x, 4)\n",
        "        conv_5 = self.get_conv_out(self.conv_5, x, 5)\n",
        "        x = torch.cat([conv_3, conv_4, conv_5], 1)\n",
        "        #x = F.dropout(x, p=self.dropout)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "152QCQuKkJUj",
        "colab": {}
      },
      "source": [
        "######################################################################\n",
        "#\n",
        "#   Architecture is as follows\n",
        "#   1. Bert word encoding + CNN with max pooling for sent.embed\n",
        "#   2. Glove & CoVe word Encoding  + CNN with attention for sent.embed\n",
        "#   3. (1) and (2) concated and fed to MLP for classification (1-sugg)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP,self).__init__()\n",
        "        self.l0 = nn.Linear(900,300) # BERT-> CNN (300), G,C->CNN (600)\n",
        "        self.l1 = nn.Linear(300,300)\n",
        "        self.l3 = nn.Linear(300,2)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.act2 = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "        # print(x.shape)\n",
        "        # print(x.type())\n",
        "        #print(\"============\")\n",
        "        #print(x)\n",
        "        x = (self.l0(x))\n",
        "        #print(x)\n",
        "        x = self.act1(x)\n",
        "        x = (self.l1(x))\n",
        "        #print(x)\n",
        "        # print(x.shape)\n",
        "        x = self.act2(x)\n",
        "        x = (self.l3(x))\n",
        "        #print(F.softmax(x))\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SuggestionClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        # path all the models together\n",
        "        # BERT->CNN + CNN->ATT\n",
        "        super(SuggestionClassifier,self).__init__()\n",
        "        self.CNN_b = CNN_BERT()\n",
        "        self.CNN_gc = CNN_GC()\n",
        "        self.MLP = MLP()\n",
        "\n",
        "\n",
        "    def forward(self,x, y):\n",
        "        #print(\"=========================\")\n",
        "        bert_x = self.CNN_b(x)\n",
        "        #print(\"Total Model\", bert_x.shape)\n",
        "        gc_x = self.CNN_gc(y)\n",
        "        #print(\"Total Model\", gc_x.shape)\n",
        "        out = torch.cat((bert_x,gc_x), 1) # TODO : ensure dimensions align (1x300, 1x600)\n",
        "        #print(\"Total\", out.shape)\n",
        "        out = self.MLP(out) # Dim : 1x900\n",
        "        #print(\"Total\", out.shape)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaQPm5XfNSvg",
        "colab_type": "code",
        "outputId": "06f39f3c-a94d-4654-8ce9-19109903fe42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#########################\n",
        "# HYPER PARAMETER TUNING\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "#WEIGHT_DECAY = 3\n",
        "BATCH_SIZE = 32\n",
        "NFOLDS = 10\n",
        "NUM_WORKERS = 16\n",
        "LEARNING_RATE = 1e-3 # TODO : Experiment, as LR not given\n",
        "\n",
        "########################\n",
        "# MODEL CREATION\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv1d:\n",
        "        torch.nn.init.xavier_normal_(m.weight.data)\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_normal_(m.weight.data)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\"\"\"\n",
        "model = SuggestionClassifier()\n",
        "# TODO:  WEIGHT INIT\n",
        "model.apply(init_weights)\n",
        "model.train()\n",
        "model.to(device)\n",
        "\n",
        "#######################\n",
        "# OPTIMIZATION\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=LEARNING_RATE, )\n",
        "\"\"\"\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmodel = SuggestionClassifier()\\n# TODO:  WEIGHT INIT\\nmodel.apply(init_weights)\\nmodel.train()\\nmodel.to(device)\\n\\n#######################\\n# OPTIMIZATION\\n\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = torch.optim.Adadelta(model.parameters(), lr=LEARNING_RATE, )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eptRSi3LNSvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#############################\n",
        "# HELPER FUNCTIONS\n",
        "\n",
        "def train(model, train_loader, valid_loader, test_loader, foldId, numEpochs,\n",
        "           outputs_cove_with_glove, outputs_cove_with_glove_test):\n",
        "    '''\n",
        "    Args:\n",
        "\n",
        "    Ret: \n",
        "    '''\n",
        "\n",
        "    model.train()\n",
        "    val_loss_min = None\n",
        "    val_loss_min_delta = 0.005\n",
        "    val_patience = 5\n",
        "    val_loss_counter = 0\n",
        "\n",
        "    # TODO : 10-fold cross validation (build 10 models)\n",
        "    # TODO : Ensemble, pick top three models based on train loss\n",
        "    # TODO : Voting Mechanism to evaluate on Validation data\n",
        "    \n",
        "    # for each fold\n",
        "    #     for each epoch\n",
        "    #       min_batch_train(model)\n",
        "    #       val_loss = model(trial_data)\n",
        "    #       early_stopping(val_loss)\n",
        "    #     models += models\n",
        "    #     three_models = select_best_3(models) based on train_loss\n",
        "        \n",
        "    for epoch in range(numEpochs):\n",
        "        avg_loss = 0.0\n",
        "        for batch_num, batch in enumerate(train_loader):\n",
        "            glove_then_last_layer_cove = outputs_cove_with_glove(*batch.sentence)\n",
        "            target = torch.zeros(glove_then_last_layer_cove.shape[0], MAX_LEN_GC, 900)\n",
        "            max_sentence_len_in_batch = max(batch.sentence[1].tolist())\n",
        "            target[:, :max_sentence_len_in_batch, :] = glove_then_last_layer_cove\n",
        "            glove_then_last_layer_cove = target.permute(0,2,1)\n",
        "            \n",
        "            bert_enc = batch.bert_enc.to(device)\n",
        "            glove_cove_enc = glove_then_last_layer_cove.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(bert_enc, glove_cove_enc)\n",
        "            _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
        "            \"\"\"\n",
        "            if batch_num % 50 == 0:\n",
        "              print(outputs)\n",
        "              print(pred_labels)\n",
        "            \"\"\"\n",
        "            #print(outputs.shape)\n",
        "            #print(outputs)\n",
        "            labels = batch.label.long()\n",
        "            labels = labels.to(device)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \"\"\"\n",
        "            if batch_num % 50 == 0:\n",
        "              print(labels)\n",
        "              print(loss)\n",
        "            \"\"\"\n",
        "            #print(loss)\n",
        "            \n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 3, norm_type=2)\n",
        "            optimizer.step()\n",
        "            \"\"\"\n",
        "            for n,p in model.named_parameters():\n",
        "                if p.requires_grad and n.startswith('MLP.l0'):\n",
        "                  print(n, p.data)\n",
        "            \"\"\"\n",
        "            #print(\"Optimizer Complete\")\n",
        "\n",
        "            avg_loss += loss.item()\n",
        "            #print(avg_loss)\n",
        "\n",
        "            if batch_num % 50 == 49:\n",
        "                print('Fold: {}\\t Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(foldId+1, \n",
        "                                                                                 epoch+1, batch_num+1, avg_loss/50))\n",
        "                avg_loss = 0.0\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            del bert_enc\n",
        "            del glove_cove_enc\n",
        "            del labels\n",
        "            \n",
        "\n",
        "        model_name = \"jessi_A_fold_\"+str(foldId+1)+\"_epoch_\"+str(epoch+1)+\".pt\"\n",
        "        #print(model.parameters())\n",
        "        \n",
        "        print('Epoch'+str(epoch))\n",
        "        val_loss, val_sc, val_acc = validate(model, valid_loader, outputs_cove_with_glove_valid)\n",
        "        test_loss, test_sc,test_acc = validate(model, test_loader, outputs_cove_with_glove_test)\n",
        "        print('Epoch{:.4f}\\tVal Loss: {:.4f}\\tVal Sc: {:.4f}\\tVal Accuracy: {:.4f}'.format(\n",
        "             epoch, val_loss, val_sc, val_acc))\n",
        "        print('Epoch{:.4f}\\tTest Loss: {:.4f}\\tTest sc: {:.4f}\\tTest Accuracy: {:.4f}'.format(\n",
        "            epoch, test_loss, test_sc,test_acc))\n",
        "        # Early stopping\n",
        "        \"\"\"\n",
        "        if val_loss_min is None:\n",
        "            val_loss_min = val_loss\n",
        "        if val_loss_min > (val_loss) :\n",
        "            val_loss_counter += 1\n",
        "            if (val_loss_counter > val_patience) :\n",
        "                print(\"Validation Loss: {}\\t Lowest Validation Loss {}\\t\".format(val_loss, val_loss_min))\n",
        "                print(\"Training stopped early, Epoch :\"+str(epoch))\n",
        "                break\n",
        "        else:\n",
        "            val_loss_min = val_loss\n",
        "            val_loss_counter = 0\n",
        "            print(\"Val loss min: \",val_loss_min)\n",
        "            print(\"Created Model: \", model_name)\n",
        "            torch.save(model.state_dict(), model_name)\n",
        "        \"\"\"\n",
        "    return test_acc, model_name #test_acc\n",
        "\n",
        "\n",
        "def validate(model, valid_loader, outputs_cove_with_glove):\n",
        "    '''\n",
        "    Args:\n",
        "\n",
        "    Ret:\n",
        "    '''\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = []\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_num, batch in enumerate(valid_loader):\n",
        "        \n",
        "        glove_then_last_layer_cove = outputs_cove_with_glove(*batch.sentence)\n",
        "        target = torch.zeros(glove_then_last_layer_cove.shape[0], MAX_LEN_GC, 900)\n",
        "        max_sentence_len_in_batch = max(batch.sentence[1].tolist())\n",
        "        target[:, :max_sentence_len_in_batch, :] = glove_then_last_layer_cove\n",
        "        glove_then_last_layer_cove = target.permute(0,2,1)\n",
        "\n",
        "        bert_enc = batch.bert_enc.to(device)\n",
        "        glove_cove_enc = glove_then_last_layer_cove.to(device)\n",
        "        #print(glove_cove_enc)\n",
        "        outputs = model(bert_enc, glove_cove_enc)\n",
        "\n",
        "        labels = batch.label.long()\n",
        "        labels = labels.to(device)\n",
        "    \n",
        "        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
        "        loss = criterion(outputs, labels).item()\n",
        "        accuracy += torch.sum(torch.eq(pred_labels, labels.to(device))).item()\n",
        "        total += len(labels)\n",
        "\n",
        "        test_loss.extend([loss]*len(labels))\n",
        "        \n",
        "        all_labels.extend(list(np.array(labels.cpu())))\n",
        "        predictions = pred_labels.cpu()\n",
        "        all_predictions.extend(list(np.array(predictions)))\n",
        "        \n",
        "\n",
        "        #torch.cuda.empty_cache()\n",
        "        del bert_enc\n",
        "        del glove_cove_enc\n",
        "        del labels\n",
        "    \n",
        "        \n",
        "\n",
        "    score = f1_score(all_labels, all_predictions)\n",
        "    print(all_labels)\n",
        "    print(all_predictions)\n",
        "    print(accuracy)\n",
        "    print(total)\n",
        "    #return 0, score\n",
        "    return np.mean(test_loss),score, accuracy/total\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_vV0LdTNSv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################\n",
        "# DATA LOADING\n",
        "\n",
        "VALID_TEXT = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
        "VALID_LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "VALID_TEXT_BERT = data.Field(\n",
        "    use_vocab=False,\n",
        "    batch_first=True,\n",
        "    pad_token=tokenizer.pad_token_id,\n",
        "    tokenize=tokenizerfnc\n",
        ")\n",
        "\n",
        "# valid_dataset = SuggestionDataset(load_data(filename=\"SubtaskA_Trial_Test_Labeled.csv\"))\n",
        "valid_path = \"/content/SubtaskA_Trial_Test_Labeled.csv\"\n",
        "valid_dataset = data.TabularDataset(\n",
        "            path=valid_path, format='csv',\n",
        "            skip_header = False,\n",
        "            fields={'sentence':[('sentence',VALID_TEXT),('bert_enc',VALID_TEXT_BERT)],\n",
        "                    'label':('label',VALID_LABEL)\n",
        "                    })\n",
        "\n",
        "VALID_TEXT.build_vocab(valid_dataset, vectors=GloVe(name='840B', dim=300, cache='/content/drive/My Drive/nn4nlpdata'))\n",
        "outputs_cove_with_glove_valid = cove.MTLSTM(n_vocab=len(VALID_TEXT.vocab), vectors=VALID_TEXT.vocab.vectors, residual_embeddings=True, model_cache='.embeddings')\n",
        "\n",
        "valid_iter = data.Iterator(\n",
        "        (valid_dataset),\n",
        "        batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g0djis4NSv-",
        "colab_type": "code",
        "outputId": "b5ae15d5-2a71-44ca-c09f-3ac03f701493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# data = load_data()\n",
        "# data_folds = create_folds(data)\n",
        "model_perfs = []\n",
        "model_names = []\n",
        "\n",
        "train_path = \"train_{}.csv\"\n",
        "test_path = \"test_{}.csv\"\n",
        "\n",
        "for i in range(NFOLDS):\n",
        "    \n",
        "    print(\"FOLD: \", i)\n",
        "    \n",
        "    model = SuggestionClassifier()\n",
        "    model.apply(init_weights)\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    TEXT = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
        "    LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "    TEXT_BERT = data.Field(\n",
        "        use_vocab=False,\n",
        "        batch_first=True,\n",
        "        pad_token=tokenizer.pad_token_id,\n",
        "        tokenize=tokenizerfnc\n",
        "    )\n",
        "\n",
        "    # train loader\n",
        "    train_dataset = data.TabularDataset(\n",
        "            path=train_path.format(i), format='csv',\n",
        "            skip_header = False,\n",
        "            fields={'sentence':[('sentence',TEXT),('bert_enc',TEXT_BERT)],\n",
        "                    'label':('label',LABEL)\n",
        "                    })\n",
        "\n",
        "    TEXT.build_vocab(train_dataset, vectors=GloVe(name='840B', dim=300, cache='/content/drive/My Drive/nn4nlpdata'))\n",
        "    outputs_cove_with_glove = cove.MTLSTM(n_vocab=len(TEXT.vocab), vectors=TEXT.vocab.vectors, \n",
        "                                     residual_embeddings=True, model_cache='.embeddings')\n",
        "\n",
        "    train_iter = data.Iterator(\n",
        "        (train_dataset),\n",
        "        batch_size=BATCH_SIZE)\n",
        "    \n",
        "    print(\"Created Train Iterator\")\n",
        "    \n",
        "    TEST_TEXT = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
        "    TEST_LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "    TEST_TEXT_BERT = data.Field(\n",
        "        use_vocab=False,\n",
        "        batch_first=True,\n",
        "        pad_token=tokenizer.pad_token_id,\n",
        "        tokenize=tokenizerfnc\n",
        "    )\n",
        "    \n",
        "    # test loader\n",
        "    test_dataset = data.TabularDataset(\n",
        "            path=test_path.format(i), format='csv',\n",
        "            skip_header = False,\n",
        "            fields={'sentence':[('sentence',TEST_TEXT),('bert_enc',TEST_TEXT_BERT)],\n",
        "                    'label':('label',TEST_LABEL)\n",
        "                    })\n",
        "\n",
        "    TEST_TEXT.build_vocab(test_dataset, vectors=GloVe(name='840B', dim=300, cache='/content/drive/My Drive/nn4nlpdata'))\n",
        "    outputs_cove_with_glove_test = cove.MTLSTM(n_vocab=len(TEST_TEXT.vocab), vectors=TEST_TEXT.vocab.vectors, \n",
        "                                          residual_embeddings=True, model_cache='/content/drive/My Drive/nn4nlpdata')\n",
        "\n",
        "    test_iter = data.Iterator(\n",
        "        (test_dataset),\n",
        "        batch_size=BATCH_SIZE)\n",
        "    \n",
        "    print(\"Created Test Iterator\")\n",
        "    \n",
        "    test_loss, model_name = train(model, train_iter, valid_iter, test_iter, i, NUM_EPOCHS, \n",
        "                                  outputs_cove_with_glove, outputs_cove_with_glove_test)\n",
        "\n",
        "    model_perfs.append(test_loss)\n",
        "    model_names.append(model_name)\n",
        "    del model\n",
        "    del criterion\n",
        "    del optimizer\n",
        "    \n",
        "print(model_perfs)\n",
        "print(model_names)\n",
        "best_three_model_idx = np.flip(np.argsort(model_perfs))[0:3]\n",
        "models = []\n",
        "for idx in best_three_model_idx:\n",
        "    # load the model\n",
        "    #temp_model = SuggestionClassifier()\n",
        "    temp_model = SuggestionClassifier()\n",
        "    temp_model.load_state_dict(torch.load(model_names[idx]))\n",
        "    models.append(temp_model)\n",
        "# testing\n",
        "print(len(models))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOLD:  0\n",
            "Created Train Iterator\n",
            "Created Test Iterator\n",
            "Epoch0\n",
            "[1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "18\n",
            "32\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "25\n",
            "32\n",
            "Epoch0.0000\tVal Loss: 1.0322\tVal Sc: 0.0000\tVal Accuracy: 0.5625\n",
            "Epoch0.0000\tTest Loss: 0.5427\tTest sc: 0.0000\tTest Accuracy: 0.7812\n",
            "Epoch1\n",
            "[1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "18\n",
            "32\n",
            "[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "28\n",
            "32\n",
            "Epoch1.0000\tVal Loss: 0.7198\tVal Sc: 0.0000\tVal Accuracy: 0.5625\n",
            "Epoch1.0000\tTest Loss: 0.4704\tTest sc: 0.0000\tTest Accuracy: 0.8750\n",
            "Epoch2\n",
            "[1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "11\n",
            "32\n",
            "[0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "7\n",
            "32\n",
            "Epoch2.0000\tVal Loss: 0.8854\tVal Sc: 0.5116\tVal Accuracy: 0.3438\n",
            "Epoch2.0000\tTest Loss: 0.9837\tTest sc: 0.3590\tTest Accuracy: 0.2188\n",
            "Epoch3\n",
            "[0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "20\n",
            "32\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "27\n",
            "32\n",
            "Epoch3.0000\tVal Loss: 0.6803\tVal Sc: 0.3333\tVal Accuracy: 0.6250\n",
            "Epoch3.0000\tTest Loss: 0.6475\tTest sc: 0.0000\tTest Accuracy: 0.8438\n",
            "Epoch4\n",
            "[0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "16\n",
            "32\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "25\n",
            "32\n",
            "Epoch4.0000\tVal Loss: 3.2765\tVal Sc: 0.0000\tVal Accuracy: 0.5000\n",
            "Epoch4.0000\tTest Loss: 1.4279\tTest sc: 0.0000\tTest Accuracy: 0.7812\n",
            "Epoch5\n",
            "[0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "15\n",
            "32\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "25\n",
            "32\n",
            "Epoch5.0000\tVal Loss: 2.3401\tVal Sc: 0.0000\tVal Accuracy: 0.4688\n",
            "Epoch5.0000\tTest Loss: 0.9723\tTest sc: 0.0000\tTest Accuracy: 0.7812\n",
            "Epoch6\n",
            "[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "17\n",
            "32\n",
            "[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "28\n",
            "32\n",
            "Epoch6.0000\tVal Loss: 0.7943\tVal Sc: 0.0000\tVal Accuracy: 0.5312\n",
            "Epoch6.0000\tTest Loss: 0.4374\tTest sc: 0.0000\tTest Accuracy: 0.8750\n",
            "Epoch7\n",
            "[0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "14\n",
            "32\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "9\n",
            "32\n",
            "Epoch7.0000\tVal Loss: 0.7681\tVal Sc: 0.6087\tVal Accuracy: 0.4375\n",
            "Epoch7.0000\tTest Loss: 0.8856\tTest sc: 0.4390\tTest Accuracy: 0.2812\n",
            "Epoch8\n",
            "[1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "15\n",
            "32\n",
            "[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "25\n",
            "32\n",
            "Epoch8.0000\tVal Loss: 1.2119\tVal Sc: 0.0000\tVal Accuracy: 0.4688\n",
            "Epoch8.0000\tTest Loss: 0.5899\tTest sc: 0.0000\tTest Accuracy: 0.7812\n",
            "Epoch9\n",
            "[1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "17\n",
            "32\n",
            "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "24\n",
            "32\n",
            "Epoch9.0000\tVal Loss: 1.1967\tVal Sc: 0.0000\tVal Accuracy: 0.5312\n",
            "Epoch9.0000\tTest Loss: 0.6882\tTest sc: 0.0000\tTest Accuracy: 0.7500\n",
            "Epoch10\n",
            "[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "16\n",
            "32\n",
            "[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "28\n",
            "32\n",
            "Epoch10.0000\tVal Loss: 0.8346\tVal Sc: 0.0000\tVal Accuracy: 0.5000\n",
            "Epoch10.0000\tTest Loss: 0.4254\tTest sc: 0.0000\tTest Accuracy: 0.8750\n",
            "Epoch11\n",
            "[0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "22\n",
            "32\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "26\n",
            "32\n",
            "Epoch11.0000\tVal Loss: 0.6599\tVal Sc: 0.2857\tVal Accuracy: 0.6875\n",
            "Epoch11.0000\tTest Loss: 0.6554\tTest sc: 0.2500\tTest Accuracy: 0.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c3d9529f66e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     test_loss, model_name = train(model, train_iter, valid_iter, test_iter, i, NUM_EPOCHS, \n\u001b[0;32m---> 74\u001b[0;31m                                   outputs_cove_with_glove, outputs_cove_with_glove_test)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mmodel_perfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a7f318177642>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, valid_loader, test_loader, foldId, numEpochs, outputs_cove_with_glove, outputs_cove_with_glove_test)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mglove_then_last_layer_cove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs_cove_with_glove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_then_last_layer_cove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LEN_GC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;31m# fast-forward if loaded from state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36minit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state_this_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restored_from_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mcreate_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_shuffler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;34m\"\"\"Shuffle and return a new list.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_internal_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m         \u001b[0;31m# invariant:  non-selected at [0,n-i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mpool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# move non-selected item into vacancy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36m_randbelow\u001b[0;34m(self, n, int, maxsize, type, Method, BuiltinMethod)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mrandom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mgetrandbits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetrandbits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Only call self.getrandbits if the original random() builtin method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m# has not been overridden or if a new getrandbits() was supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTp9m3GkpQjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loop(i):\n",
        "  model = SuggestionClassifier()\n",
        "  model.eval()\n",
        "  \n",
        "  model.load_state_dict(torch.load('jessi_A_fold_{}_epoch_4.pt'.format(i+1)))\n",
        "  model.to(device)\n",
        "  valid_path='/content/SubtaskA_EvaluationData_labeled.csv' #'test_{}.csv'.format(i)\n",
        "    # test loader\n",
        "\n",
        "  TEST_TEXT = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
        "  TEST_LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "  TEST_TEXT_BERT = data.Field(\n",
        "        use_vocab=False,\n",
        "        batch_first=True,\n",
        "        pad_token=tokenizer.pad_token_id,\n",
        "        tokenize=tokenizerfnc\n",
        "    )\n",
        "  test_dataset = data.TabularDataset(\n",
        "            path=valid_path, format='csv',\n",
        "            skip_header = False,\n",
        "            fields={'sentence':[('sentence',TEST_TEXT),('bert_enc',TEST_TEXT_BERT)],\n",
        "                    'label':('label',TEST_LABEL)\n",
        "                    })\n",
        "  TEST_TEXT.build_vocab(test_dataset, vectors=GloVe(name='840B', dim=300, cache='/content/drive/My Drive/nn4nlpdata'))\n",
        "  outputs_cove_with_glove_test = cove.MTLSTM(n_vocab=len(TEST_TEXT.vocab), vectors=TEST_TEXT.vocab.vectors, \n",
        "                                          residual_embeddings=True, model_cache='/content/drive/My Drive/nn4nlpdata')\n",
        "  test_iter = data.Iterator(\n",
        "        (test_dataset),\n",
        "        batch_size=BATCH_SIZE)\n",
        "  score, acc = validate(model, test_iter, outputs_cove_with_glove_test)\n",
        "  print('Epoch'+str(i),score,acc)\n",
        "  del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_qHja01smdv",
        "colab_type": "code",
        "outputId": "2aca9dd4-fb21-413c-b223-6d46320f3259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "\n",
        "for i in range(4,5):\n",
        "  loop(i)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "726\n",
            "833\n",
            "Epoch4 0.5523012552301255 0.8715486194477791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mU2g0FNIWCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = []\n",
        "for item in [(2,5),(3,6),(5,4)]:\n",
        "  model = SuggestionClassifier()\n",
        "  model.load_state_dict(torch.load('jessi_A_fold_{}_epoch_{}.pt'.format(item[0],item[1])))\n",
        "  models.append(model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX_HEMafNSwG",
        "colab_type": "code",
        "outputId": "04772e5d-8241-49a4-e09e-eb4915f0d48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def test(models, test_loader, outputs_cove_with_glove, id_map=0):\n",
        "    '''\n",
        "    Args:\n",
        "\n",
        "    Ret:\n",
        "    '''\n",
        "\n",
        "    test_loss = []\n",
        "    accuracy = 0\n",
        "    total = 0\n",
        "    \n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    outcomes = []\n",
        "    \n",
        "    for batch_num, batch in enumerate(test_loader):\n",
        "\n",
        "        glove_then_last_layer_cove = outputs_cove_with_glove(*batch.sentence)\n",
        "        target = torch.zeros(glove_then_last_layer_cove.shape[0], MAX_LEN_GC, 900)\n",
        "        max_sentence_len_in_batch = max(batch.sentence[1].tolist())\n",
        "        target[:, :max_sentence_len_in_batch, :] = glove_then_last_layer_cove\n",
        "        glove_then_last_layer_cove = target.permute(0,2,1)\n",
        "\n",
        "        bert_enc = batch.bert_enc.to(device)\n",
        "        glove_cove_enc = glove_then_last_layer_cove.to(device)\n",
        "        \n",
        "        predictions = torch.tensor(np.zeros(len(batch.label)))\n",
        "\n",
        "        for model in models:\n",
        "            model.eval()\n",
        "            model.to(device)\n",
        "            outputs = model(bert_enc, glove_cove_enc)\n",
        "            \n",
        "            _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
        "            # print(np.array(pred_labels.view(-1).cpu()))\n",
        "            predictions += pred_labels.view(-1).cpu()\n",
        "            model.train()\n",
        "            del model\n",
        "\n",
        "        predictions = torch.round(predictions/3)\n",
        "        \n",
        "        labels = batch.label.long()\n",
        "        \n",
        "        accuracy += torch.sum(torch.eq(predictions, labels))\n",
        "        total += len(labels)\n",
        "        \n",
        "        all_labels.extend(list(np.array(labels)))\n",
        "        \n",
        "        predictions = np.array(predictions)\n",
        "        all_predictions.extend(list(predictions))\n",
        "        \n",
        "        outcomes += [ ['ID','SENT',predictions[i]] for i in range(len(predictions)) ]\n",
        "        \n",
        "        del bert_enc\n",
        "        del glove_cove_enc\n",
        "        del labels\n",
        "        \n",
        "        break\n",
        "    \n",
        "    f = open(\"result.csv\", \"w\", newline=\"\")\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(outcomes)\n",
        "    f.close()\n",
        "    \n",
        "    score = f1_score(all_labels, all_predictions)\n",
        "    # print(all_labels, all_predictions)\n",
        "    print(\"F1 Score:\", str(score))\n",
        "    \n",
        "    #return np.mean(test_loss), accuracy/total\n",
        "    return accuracy/total, score\n",
        "\n",
        "\n",
        "TEXT = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
        "LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "TEXT_BERT = data.Field(\n",
        "    use_vocab=False,\n",
        "    batch_first=True,\n",
        "    pad_token=tokenizer.pad_token_id,\n",
        "    tokenize=tokenizerfnc\n",
        ")\n",
        "\n",
        "test_path = \"/content/SubtaskA_EvaluationData_labeled.csv\"\n",
        "test_dataset = data.TabularDataset(\n",
        "            path=test_path, format='csv',\n",
        "            skip_header = False,\n",
        "            fields={'sentence':[('sentence',TEXT),('bert_enc',TEXT_BERT)],\n",
        "                    'label':('label',LABEL)\n",
        "                    })\n",
        "\n",
        "\n",
        "TEXT.build_vocab(test_dataset, vectors=GloVe(name='840B', dim=300, cache='/content/drive/My Drive/nn4nlpdata'))\n",
        "outputs_cove_with_glove = cove.MTLSTM(n_vocab=len(TEXT.vocab), vectors=TEXT.vocab.vectors, residual_embeddings=True, model_cache='.embeddings')\n",
        "\n",
        "\n",
        "test_iter = data.Iterator(\n",
        "        (test_dataset),\n",
        "        batch_size=16)\n",
        "\n",
        "acc,score = test(models, test_iter, outputs_cove_with_glove)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score: 0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMh_th10DiHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f433de35-02bc-466d-fff7-7dc6489f026e"
      },
      "source": [
        "print(acc,score)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0) 0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDoW4IG8NSwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i = 1\n",
        "# train_path = \"C:\\\\Users\\\\thank\\\\Downloads\\\\CMU MCDS\\\\11747\\\\project\\suggestionMining\\\\data\\\\Subtask-A\\\\train_{}.csv\"\n",
        "# test_path = \"C:\\\\Users\\\\thank\\\\Downloads\\\\CMU MCDS\\\\11747\\\\project\\suggestionMining\\\\data\\\\Subtask-A\\\\test_{}.csv\"\n",
        "\n",
        "# TEXT = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
        "# LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "# TEXT_BERT = data.Field(\n",
        "#     use_vocab=False,\n",
        "#     batch_first=True,\n",
        "#     pad_token=tokenizer.pad_token_id,\n",
        "#     tokenize=tokenizerfnc\n",
        "# )\n",
        "\n",
        "# # train loader\n",
        "# train_dataset = data.TabularDataset(\n",
        "#         path=train_path.format(i), format='csv',\n",
        "#         skip_header = False,\n",
        "#         fields={'sentence':[('sentence',TEXT),('bert_enc',TEXT_BERT)],\n",
        "#                 'label':('label',LABEL)\n",
        "#                 })\n",
        "\n",
        "# TEXT.build_vocab(train_dataset, vectors=GloVe(name='840B', dim=300, cache='.embeddings'))\n",
        "# outputs_cove_with_glove = MTLSTM(n_vocab=len(TEXT.vocab), vectors=TEXT.vocab.vectors, residual_embeddings=True, model_cache='.embeddings')\n",
        "\n",
        "# train_iter = data.Iterator(\n",
        "#     (train_dataset),\n",
        "#     batch_size=5)\n",
        "\n",
        "\n",
        "# print(\"Created Train Iterator\")\n",
        "\n",
        "# TEST_TEXT = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
        "# TEST_LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "# TEST_TEXT_BERT = data.Field(\n",
        "#     use_vocab=False,\n",
        "#     batch_first=True,\n",
        "#     pad_token=tokenizer.pad_token_id,\n",
        "#     tokenize=tokenizerfnc\n",
        "# )\n",
        "\n",
        "# # test loader\n",
        "# test_dataset = data.TabularDataset(\n",
        "#         path=test_path.format(i), format='csv',\n",
        "#         skip_header = False,\n",
        "#         fields={'sentence':[('sentence',TEST_TEXT),('bert_enc',TEST_TEXT_BERT)],\n",
        "#                 'label':('label',TEST_LABEL)\n",
        "#                 })\n",
        "\n",
        "# TEST_TEXT.build_vocab(test_dataset, vectors=GloVe(name='840B', dim=300, cache='.embeddings'))\n",
        "# outputs_cove_with_glove_test = MTLSTM(n_vocab=len(TEST_TEXT.vocab), vectors=TEST_TEXT.vocab.vectors, residual_embeddings=True, model_cache='.embeddings')\n",
        "\n",
        "# test_iter = data.Iterator(\n",
        "#     (test_dataset),\n",
        "#     batch_size=5)\n",
        "\n",
        "# print(\"Created Test Iterator\")\n",
        "\n",
        "# for batch_num, batch in enumerate(train_iter):\n",
        "#     avg_loss = 0.0\n",
        "#     glove_then_last_layer_cove = outputs_cove_with_glove(*batch.sentence)\n",
        "#     target = torch.zeros(5, 512, 900)\n",
        "#     max_sentence_len_in_batch = max(batch.sentence[1].tolist())\n",
        "#     target[:, :max_sentence_len_in_batch, :] = glove_then_last_layer_cove\n",
        "#     glove_then_last_layer_cove = target.permute(0,2,1)\n",
        "\n",
        "#     bert_enc = batch.bert_enc.to(device)\n",
        "#     glove_cove_enc = glove_then_last_layer_cove.to(device)\n",
        "\n",
        "#     optimizer.zero_grad()\n",
        "#     outputs = model(bert_enc, glove_cove_enc)\n",
        "#     print(outputs.shape)\n",
        "#     target = batch.label.reshape(5,1)\n",
        "#     print(target.shape)\n",
        "\n",
        "#     print(outputs, target)\n",
        "#     loss = criterion(outputs, batch.label.long())\n",
        "#     print(loss)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     print(\"Optimizer Complete\")\n",
        "\n",
        "#     avg_loss += loss.item()\n",
        "#     print(avg_loss)\n",
        "\n",
        "#     if batch_num % 50 == 49:\n",
        "#         print('Fold: {}\\t Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(foldId+1, epoch+1, batch_num+1, avg_loss/50))\n",
        "#         avg_loss = 0.0\n",
        "\n",
        "#     torch.cuda.empty_cache()\n",
        "#     del bert_enc\n",
        "#     del glove_cove_enc\n",
        "\n",
        "#     break\n",
        "\n",
        "\n",
        "# models = []\n",
        "# temp_model = SuggestionClassifier()\n",
        "# temp_model.load_state_dict(torch.load('jessi_A_fold_1_epoch_1.pt'))\n",
        "# models.append(temp_model)\n",
        "# temp_model = SuggestionClassifier()\n",
        "# temp_model.load_state_dict(torch.load('jessi_A_fold_2_epoch_1.pt'))\n",
        "# models.append(temp_model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}